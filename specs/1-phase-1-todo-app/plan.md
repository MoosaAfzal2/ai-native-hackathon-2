# Implementation Plan: Phase I - In-Memory Console Todo Application

**Branch**: `1-phase-1-todo-app` | **Date**: 2025-12-06 | **Spec**: [spec.md](spec.md)
**Input**: Feature specification from `/specs/1-phase-1-todo-app/spec.md`

## Summary

Build a Python 3.13+ console-based todo application implementing 5 core features (Add, View, Update, Delete, Mark Complete) with in-memory storage. The application uses a layered architecture (Models → Storage → UI → Main) following OOP principles with mandatory TDD development (Red-Green-Refactor cycle). All code must include type hints, PEP 8 compliance, and achieve 80%+ test coverage. Uses standard library only, initialized with `uv` package manager and tested with pytest.

## Technical Context

**Language/Version**: Python 3.13+
**Primary Dependencies**: pytest (dev), standard library only (runtime)
**Storage**: In-memory dictionary-based task storage (no database)
**Testing**: pytest with TDD Red-Green-Refactor cycle
**Target Platform**: Linux (WSL 2), macOS, native Linux
**Project Type**: Single console application
**Performance Goals**: Handle 100+ tasks in single session without degradation
**Constraints**: In-memory only (Phase I), sequential user interaction, no persistence
**Scale/Scope**: 5 core features, single-user, console UI, ~500-800 lines of code expected

## Constitution Check

**Status**: ✅ PASS - All requirements aligned

| Principle | Gate | Status |
|-----------|------|--------|
| **Code Quality** | All code must follow PEP 8; type hints on all functions/methods; docstrings on all classes/public methods | ✅ REQUIRED in plan |
| **OOP Design** | Clear separation between models, business logic, UI layers; single responsibility principle | ✅ Layered architecture (4 layers) |
| **TDD (NON-NEGOTIABLE)** | Red-Green-Refactor cycle mandatory; tests written FIRST; high coverage for business logic | ✅ TDD workflow defined |
| **Testing Framework** | pytest for all unit tests; tests mirror source structure | ✅ pytest + coverage |
| **Type Hints** | Required on all functions/methods | ✅ Required throughout |
| **Code Formatting** | All code formatted with ruff | ✅ Included in workflow |
| **Error Handling** | Validate all inputs; handle edge cases; clear error messages | ✅ Input validation layer |
| **Storage** | In-memory only; no database/persistence in Phase I | ✅ In-memory storage layer |

**Re-evaluation After Phase 1 Design**: Will verify no violations introduced.

## Project Structure

### Documentation (this feature)

```text
specs/1-phase-1-todo-app/
├── plan.md              # This file
├── research.md          # Phase 0: Technology research (if needed)
├── data-model.md        # Phase 1: Entity definitions
├── quickstart.md        # Phase 1: Developer quickstart
├── contracts/           # Phase 1: Interface specifications
├── checklists/
│   └── requirements.md  # Specification validation
└── tasks.md             # Phase 2: Task breakdown (generated by /sp.tasks)
```

### Source Code (repository root)

```text
console-todo-app/
├── src/
│   └── console_todo_app/
│       ├── __init__.py
│       ├── models/
│       │   ├── __init__.py
│       │   └── task.py          # Task dataclass with validation
│       ├── storage/
│       │   ├── __init__.py
│       │   └── task_storage.py  # TaskStorage with CRUD + ID generation
│       ├── ui/
│       │   ├── __init__.py
│       │   └── console_ui.py    # ConsoleUI for all user interaction
│       └── main.py              # Application entry point + event loop
├── tests/
│   ├── __init__.py
│   ├── test_task.py             # Task model unit tests (TDD)
│   ├── test_task_storage.py     # Storage layer unit tests (TDD)
│   └── test_console_ui.py       # UI layer tests (if applicable)
├── README.md                    # Setup and usage instructions
├── pyproject.toml               # UV project config
└── .gitignore                   # Python-specific ignores
```

**Structure Decision**: Single console application with layered architecture. Follows Standard Library + pytest convention. Uses dataclass-based models with in-memory dictionary storage. Clean separation between Models (data), Storage (business logic), UI (user interaction), and Main (orchestration).

## Architecture Overview

### 1. Models Layer (`models/task.py`)

**Purpose**: Data definition and validation

**Components**:
- `Task` dataclass/class:
  - Attributes: `id` (int), `title` (str), `description` (str), `created_at` (datetime), `is_complete` (bool)
  - Validation methods: validate title length (1-200), description length (max 1000)
  - Status methods: `mark_complete()`, `mark_incomplete()`, `toggle_status()`
  - Type hints on all attributes and methods
  - Docstrings explaining purpose and constraints

**Responsibilities**:
- Store task data
- Validate data constraints (title/description length)
- Provide status toggling methods
- Maintain immutability of id, created_at

**Testing Strategy**:
- Unit tests for all validation methods
- Test boundary conditions (0 chars, 200 chars, 1001 chars)
- Test status transitions
- Test immutability of id and created_at

### 2. Storage Layer (`storage/task_storage.py`)

**Purpose**: In-memory data management and business logic

**Components**:
- `TaskStorage` class:
  - Internal state: `_tasks` dict (id → Task), `_next_id` counter
  - Methods:
    - `add_task(title: str, description: str = "") → Task` - Creates and stores task
    - `get_task(task_id: int) → Task` - Retrieves single task or raises exception
    - `get_all_tasks() → List[Task]` - Returns all tasks in creation order
    - `update_task(task_id: int, title: str, description: str) → Task` - Updates task
    - `delete_task(task_id: int) → bool` - Removes task
    - `mark_complete(task_id: int) → Task` - Toggles completion status
    - `task_exists(task_id: int) → bool` - Checks existence

**Responsibilities**:
- Maintain task collection
- Generate sequential IDs (starting at 1)
- CRUD operations with validation
- Ensure data consistency
- Provide query methods

**Testing Strategy**:
- Unit tests for all CRUD operations
- Test ID generation (sequential, starting at 1)
- Test boundary conditions (empty list, non-existent IDs)
- Test data consistency across operations
- Test order preservation

### 3. UI Layer (`ui/console_ui.py`)

**Purpose**: Console interaction and formatting

**Components**:
- `ConsoleUI` class:
  - Methods:
    - `display_menu() → str` - Shows main menu, returns user choice
    - `get_input(prompt: str) → str` - Gets user input with validation
    - `display_tasks(tasks: List[Task])` - Displays tasks in table format
    - `display_task(task: Task)` - Shows single task
    - `display_message(message: str, type: str)` - Shows success/error/info
    - `format_task_table(tasks: List[Task]) → str` - Formats tasks as table
    - `format_status_symbol(is_complete: bool) → str` - Returns ✓ or ○

**Responsibilities**:
- Display main menu
- Get and validate user input
- Format and display task lists (table with ID | Title | Status | Date)
- Display status symbols (✓ complete, ○ incomplete)
- Show error and success messages
- Handle input retry loop (unlimited retries, "back"/"menu" escapes)

**Testing Strategy**:
- Unit tests for formatting functions
- Test table generation with various task counts
- Test status symbol formatting
- Test menu display
- Integration tests for input/output flow

### 4. Main Application (`main.py`)

**Purpose**: Application orchestration and event loop

**Components**:
- `TodoApp` class:
  - Initialization: Create TaskStorage and ConsoleUI
  - Methods:
    - `run()` - Main event loop
    - `handle_add_task()` - Orchestrate add operation
    - `handle_view_tasks()` - Orchestrate view operation
    - `handle_update_task()` - Orchestrate update operation
    - `handle_delete_task()` - Orchestrate delete operation
    - `handle_mark_complete()` - Orchestrate mark complete operation
  - Entry point: `if __name__ == "__main__": TodoApp().run()`

**Responsibilities**:
- Coordinate UI and Storage
- Main event loop (show menu → handle action → repeat)
- Route user actions to appropriate handlers
- Handle application exit

**Testing Strategy**:
- Integration tests for full workflows
- Test menu loop behavior
- Test error handling for each action

## Data Model

### Task Entity

```python
@dataclass
class Task:
    id: int                    # Unique sequential integer (1, 2, 3...), immutable
    title: str                 # Required, 1-200 characters
    description: str           # Optional, max 1000 characters (default: "")
    created_at: datetime       # Immutable, set at creation
    is_complete: bool          # Mutable, default False

    # Methods:
    def toggle_status() -> None: ...
    def mark_complete() -> None: ...
    def mark_incomplete() -> None: ...
    def validate() -> bool: ...  # Check title/description constraints
```

### TaskStorage State

```python
class TaskStorage:
    _tasks: dict[int, Task]    # id -> Task mapping, maintains insertion order
    _next_id: int              # Counter for sequential ID generation (starts at 1)
```

### Menu Options

```
=== Todo Application ===
1. Add Task
2. View Tasks
3. Update Task
4. Delete Task
5. Mark Complete/Incomplete
6. Exit

Select an option (1-6 or type action name): _
```

## Error Handling Strategy

| Scenario | Handling |
|----------|----------|
| Empty title | Validation error: "Title required. Enter 1-200 characters." |
| Title too long | Validation error: "Title too long (max 200). Current: X characters." |
| Description too long | Validation error: "Description too long (max 1000). Current: X characters." |
| Non-existent task ID | Error: "Task ID X not found. Please enter a valid ID." |
| Invalid menu choice | Error: "Invalid option. Please select 1-6 or enter action name." |
| Non-numeric task ID | Error: "Please enter a valid task ID (numeric)." |
| Empty user input | Prompt again: "Input required. Please try again." |
| User requests "back"/"menu" | Return to main menu without processing |

## UI/UX Specifications

### Task List Display Format

```
ID | Title                | Status   | Created
---|----------------------|----------|------------------
1  | Buy groceries        | ○        | 2025-12-06 10:30
2  | Write documentation | ✓        | 2025-12-06 10:35
3  | Review pull requests | ○        | 2025-12-06 11:00
```

### Navigation Flow

1. **Application Start** → Display main menu
2. **User Selects Action** → Execute action handler
3. **Operation Complete** → Display success message
4. **Return to Menu** → Show main menu again (loop)
5. **User Selects Exit** → Graceful shutdown

### Input Retry Strategy

- **Unlimited retries** for all input prompts
- User can type "back" or "menu" at any input prompt to return to main menu
- Clear feedback on invalid input
- Helpful error messages guiding correct format

## Development Workflow (Red-Green-Refactor)

### Phase 0: Project Setup
1. Create project structure with `uv init --package console-todo-app`
2. Add pytest: `uv add --dev pytest`
3. Create directory structure (src/, tests/, etc.)
4. Add initial files with stubs

### Phase 1: Models Layer (TDD)
**RED**:
1. Write test_task.py with comprehensive test cases:
   - Test Task instantiation with all attributes
   - Test title validation (length constraints)
   - Test description validation (length constraints)
   - Test status methods (toggle, mark complete, mark incomplete)
   - Test immutability of id and created_at
   - Test edge cases (whitespace, boundary lengths)

**GREEN**:
2. Implement Task class to pass all tests

**REFACTOR**:
3. Clean up Task implementation, optimize methods

### Phase 2: Storage Layer (TDD)
**RED**:
1. Write test_task_storage.py with comprehensive test cases:
   - Test add_task creates task with sequential ID
   - Test get_task retrieves correct task
   - Test get_all_tasks returns all tasks in order
   - Test update_task modifies title/description
   - Test update_task prevents ID/created_at changes
   - Test delete_task removes task
   - Test mark_complete toggles status
   - Test task_exists checks correctly
   - Test error handling for non-existent tasks
   - Test boundary conditions (empty storage, 100+ tasks)

**GREEN**:
2. Implement TaskStorage class to pass all tests

**REFACTOR**:
3. Clean up TaskStorage implementation, optimize CRUD operations

### Phase 3: UI Layer (TDD + Integration)
**RED**:
1. Write test_console_ui.py with test cases:
   - Test format_task_table generates correct output
   - Test format_status_symbol returns ✓ or ○
   - Test display functions don't crash
   - Test menu display structure
   - Test input handling (capture user input)

**GREEN**:
2. Implement ConsoleUI class to pass tests

**REFACTOR**:
3. Clean up UI implementation, improve formatting

### Phase 4: Main Application
1. Implement TodoApp class with event loop
2. Implement action handlers for each menu option
3. Wire up Storage and UI
4. Manual testing of full workflows
5. Verify exit handling

### Phase 5: Testing & Quality
1. Run full test suite: `uv run pytest`
2. Check coverage: `uv run pytest --cov=src`
3. Verify 80%+ coverage of business logic
4. Run ruff formatting: `uv run ruff check src/`
5. Manual testing of all 5 features
6. Test edge cases and error scenarios
7. Verify Constitution compliance

### Phase 6: Documentation
1. Write README with:
   - Project description
   - Setup instructions (uv init, uv add --dev pytest)
   - Running the application
   - Running tests
   - Code structure overview
2. Add inline docstrings/comments

## Success Metrics

| Metric | Target | Verification |
|--------|--------|--------------|
| Unit test coverage | 80%+ for models/storage | `uv run pytest --cov=src` |
| All tests pass | 100% | `uv run pytest` returns 0 |
| 5 features implemented | All working | Manual testing |
| Code follows PEP 8 | 100% | `uv run ruff check src/` |
| Type hints present | All functions/methods | Code review |
| Docstrings present | All classes/public methods | Code review |
| No unhandled exceptions | All edge cases handled | Manual testing + testing |
| Constitution compliant | All principles | Checklist verification |

## Next Steps

1. **Phase 0 (if needed)**: Run research investigation for any technology clarifications
2. **Phase 1**: Create data-model.md and interface contracts
3. **Phase 2**: Run `/sp.tasks` to generate detailed task breakdown with TDD specifications
4. **Implementation**: Follow /sp.tasks output for Red-Green-Refactor development
5. **Quality**: Run full test suite and verify success metrics

## Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|-----------|--------|-----------|
| Test coverage below 80% | Low | Medium | TDD-first approach ensures coverage; monitoring during Phase 2 |
| ID generation conflict | Very Low | High | Sequential integers prevent conflicts; tested thoroughly |
| Input validation gaps | Medium | Medium | Comprehensive test cases in Phase 1 catch edge cases |
| UI formatting issues | Low | Low | Table formatting tested; manual verification in Phase 4 |
| Performance degradation | Very Low | Low | 100+ task test case validates performance |


